---
title: Entropia Informacional
tags: [entropia, informação]
created: 2025-08-28
updated: 2025-09-04
---
# Entropia Informacional

- A entropia informacional, na perspectiva [[Descentralismo|descentralista]] adotada aqui, é [[Objetivo|objetiva]] e intrínseca à informação, e não relativa a um modelo ou um código, como a [[Entropia de Shannon]]. Pelo mesmo motivo, a entropia informacional descentralista não usa o conceito de [[Incerteza]], já que essa é relativa a um modelo.
- Mais respostas em [[Entropia Informacional - Perguntas e Respostas]]
## Definição descentralista (ontológica)
- Objetiva e não relativa ao observador: diferentes modelos locais podem divergir, mas todos são constrangidos pelas mesmas regras naturais; o resíduo que persiste apesar desses modelos caracteriza a entropia informacional?
- Complementar de ordem: ordem informacional é a estabilização de padrões que conservam diferenças úteis; entropia informacional é o saldo de variação que não foi capturado por tais padrões.
- Seta do tempo: cresce globalmente com a acumulação de contingências e misturas; pode cair localmente quando processos de seleção e aprendizado descobrem ou formam novos padrões estáveis.
- Operacionalidade: na prática, aproximamos esta noção buscando descrições parcimoniosas que preservem o essencial e separem o que é apenas contingente; medidas estatísticas ajudam como instrumentos, mas não constituem a definição ontológica.

## Relação com leituras clássicas
- Shannon: oferece medidas relativas a modelos e canais que são excelentes ferramentas operacionais (incerteza, correlação), mas não esgotam a definição ontológica aqui adotada.
- Kolmogorov/descrição mínima: captura a intuição de que padrões reais permitem simplificação objetiva; quanto menos um estado admite ser simplificado à luz das leis, maior o seu saldo de dispersão informacional.

## Seta do tempo
- Em sistemas fechados, sob coarse-graining fixo, a entropia informacional tende a crescer (perda de distinções, irreversibilidade sob o código). A seta do tempo é o acúmulo de traços/seleções.
- Códigos que evoluem podem reduzir entropia local (capturando novas correlações), enquanto o saldo global de ruído relativo a códigos mais pobres pode aumentar.

## Encadeamento conceitual
- Fundamenta o [[Espaço-Tempo|tempo]]: a seta do tempo emerge do crescimento de entropia informacional (sob um recorte/código).
- [[Utilidade]] depende do tempo (decisão, processo, custo, oportunidade); portanto, utilidade não fundamenta entropia.

## Difere de entropia energética
- Não confundir com [[Entropia Energética]]: a energética trata da dispersão de energia sob leis termodinâmicas; a informacional mede incerteza/ruído relativo a um código. Em sistemas físicos, conectam-se via codificação de micro/macroestados.

## Medir na prática
- Estime distribuições para H/I; use compressores como proxy de K; monitore erro preditivo e robustez.
- Em [[Aprendizado de Máquina]], generalização é compressão útil (ordem); overfitting é pseudo-ordem que não reduz entropia fora do treino.

## Ligações
- Conecta [[Informação]] e processos de atualização em [[Virtualidade]].
- Importante para [[Descentralismo]] (feedbacks, ruído vs sinal).
- Relaciona-se a [[Compressão de Informação]] (ordem vs dispersão; redundância vs ruído).
- Relaciona [[Cosmologia Informacional]], [[Controle]] e [[Lei da Variedade Requisitada]].

## Fontes externas (referência)
- ../Articles/Drafts/Virtualidade e Informação - Da Virtualidade Deleuziana à Entropia Informacional.txt
